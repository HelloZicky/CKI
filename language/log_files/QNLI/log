{'time': '2024-05-13 03:53:31.915186', 'qnli_dev_eval_loss': 0.6937954425811768, 'qnli_dev_eval_acc': 0.5053999633900788, 'qnli_test_eval_loss': 0.6937954425811768, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/QNLI', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-unimodel-32-1e-3', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-unimodel-32-1e-3/runs/May13_03-40-13_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-unimodel-32-1e-3', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-unimodel-32-1e-3', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'unimodel', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'qnli', 'data_dir': '../data/original/QNLI', 'max_seq_length': 128, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 07:12:24.060872', 'qnli_dev_eval_loss': 0.6539662480354309, 'qnli_dev_eval_acc': 0.6692293611568735, 'qnli_test_eval_loss': 0.6539662480354309, 'qnli_test_eval_acc': 0.6692293611568735, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/QNLI', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-uniting-32-1e-3', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-uniting-32-1e-3/runs/May13_03-36-38_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-uniting-32-1e-3', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-uniting-32-1e-3', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'uniting', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'qnli', 'data_dir': '../data/original/QNLI', 'max_seq_length': 128, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 13:04:09.842874', 'qnli_dev_eval_loss': 0.6938191056251526, 'qnli_dev_eval_acc': 0.5053999633900788, 'qnli_test_eval_loss': 0.6938191056251526, 'qnli_test_eval_acc': 0.5053999633900788, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/QNLI', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-averaging-32-1e-2', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.01, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-averaging-32-1e-2/runs/May13_12-48-14_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-averaging-32-1e-2', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-averaging-32-1e-2', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'averaging', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'qnli', 'data_dir': '../data/original/QNLI', 'max_seq_length': 128, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 15:59:36.851995', 'qnli_dev_eval_loss': 0.5274066925048828, 'qnli_dev_eval_acc': 0.7413509060955519, 'qnli_test_eval_loss': 0.5274066925048828, 'qnli_test_eval_acc': 0.7413509060955519, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/QNLI', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-ensemble-32-1e-2', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.01, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-ensemble-32-1e-2/runs/May13_12-47-02_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-ensemble-32-1e-2', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-ensemble-32-1e-2', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'ensemble', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'qnli', 'data_dir': '../data/original/QNLI', 'max_seq_length': 128, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 16:39:11.217317', 'qnli_dev_eval_loss': 0.6931471824645996, 'qnli_dev_eval_acc': 0.4946000366099213, 'qnli_test_eval_loss': 0.6931471824645996, 'qnli_test_eval_acc': 0.4946000366099213, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/QNLI', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-pruning-32-1e-2-v2', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.01, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-pruning-32-1e-2-v2/runs/May13_13-27-26_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-pruning-32-1e-2-v2', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/QNLI/QNLI-finetune-roberta-base-pruning-32-1e-2-v2', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'pruning', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'qnli', 'data_dir': '../data/original/QNLI', 'max_seq_length': 128, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': None, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
