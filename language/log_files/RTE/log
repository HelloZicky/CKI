{'time': '2024-05-13 09:32:21.342106', 'rte_dev_eval_loss': 0.6763479113578796, 'rte_dev_eval_acc': 0.5884476534296029, 'rte_test_eval_loss': 0.6763479113578796, 'rte_test_eval_acc': 0.5884476534296029, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-pruning-32-1e-3', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-pruning-32-1e-3/runs/May13_09-31-34_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-pruning-32-1e-3', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-pruning-32-1e-3', 'uniting_learning_rate': 0.001, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'pruning', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 09:33:33.908191', 'rte_dev_eval_loss': 0.6843658089637756, 'rte_dev_eval_acc': 0.5848375451263538, 'rte_test_eval_loss': 0.6843658089637756, 'rte_test_eval_acc': 0.5848375451263538, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-1e-3', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-1e-3/runs/May13_09-32-47_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-1e-3', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-1e-3', 'uniting_learning_rate': 0.001, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'ensemble', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 09:35:14.226990', 'rte_dev_eval_loss': 0.699098527431488, 'rte_dev_eval_acc': 0.4729241877256318, 'rte_test_eval_loss': 0.699098527431488, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-uniting-32-1e-3', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-uniting-32-1e-3/runs/May13_09-34-01_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-uniting-32-1e-3', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-uniting-32-1e-3', 'uniting_learning_rate': 0.001, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'uniting', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 09:45:56.994522', 'rte_dev_eval_loss': 0.698335587978363, 'rte_dev_eval_acc': 0.4729241877256318, 'rte_test_eval_loss': 0.698335587978363, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.01, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-/runs/May13_09-45-50_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'ensemble', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 12:49:04.776144', 'rte_dev_eval_loss': 0.6969469785690308, 'rte_dev_eval_acc': 0.4729241877256318, 'rte_test_eval_loss': 0.6969469785690308, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-averaging-32-1e-2', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.01, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-averaging-32-1e-2/runs/May13_12-48-57_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-averaging-32-1e-2', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-averaging-32-1e-2', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'averaging', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 12:52:14.142086', 'rte_dev_eval_loss': 0.693834125995636, 'rte_dev_eval_acc': 0.4729241877256318, 'rte_test_eval_loss': 0.693834125995636, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-uniting-32-1e-2', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.01, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-uniting-32-1e-2/runs/May13_12-51-08_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-uniting-32-1e-2', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-uniting-32-1e-2', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'uniting', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 12:52:50.283954', 'rte_dev_eval_loss': 0.6965075731277466, 'rte_dev_eval_acc': 0.4729241877256318, 'rte_test_eval_loss': 0.6965075731277466, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-unimodel-32-1e-2', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.01, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-unimodel-32-1e-2/runs/May13_12-52-43_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-unimodel-32-1e-2', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-unimodel-32-1e-2', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'unimodel', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 12:59:54.794670', 'rte_dev_eval_loss': 0.6931471824645996, 'rte_dev_eval_acc': 0.5270758122743683, 'rte_test_eval_loss': 0.6931471824645996, 'rte_test_eval_acc': 0.5270758122743683, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-pruning-32-', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.01, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-pruning-32-/runs/May13_12-58-35_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-pruning-32-', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-pruning-32-', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'pruning', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-13 13:24:12.090111', 'rte_dev_eval_loss': 0.7248783707618713, 'rte_dev_eval_acc': 0.5884476534296029, 'rte_test_eval_loss': 0.7248783707618713, 'rte_test_eval_acc': 0.5884476534296029, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-1e-2-v2', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.01, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 0.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-1e-2-v2/runs/May13_13-23-24_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-1e-2-v2', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-ensemble-32-1e-2-v2', 'uniting_learning_rate': 0.01, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'ensemble', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-14 02:58:30.447860', 'rte_dev_eval_loss': 0.6965075731277466, 'rte_dev_eval_acc': 0.4729241877256318, 'rte_test_eval_loss': 0.6965075731277466, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': 0, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0/runs/May14_02-57-44_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'uniting_learning_rate': 0.001, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'finetune', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-14 03:03:52.101210', 'rte_dev_eval_loss': 0.6965075731277466, 'rte_dev_eval_acc': 0.4729241877256318, 'rte_test_eval_loss': 0.6965075731277466, 'rte_test_eval_acc': 0.4729241877256318, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0/runs/May14_03-02-22_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'uniting_learning_rate': 0.001, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'finetune', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-14 03:33:57.641146', 'rte_dev_eval_loss': 0.6928142309188843, 'rte_dev_eval_acc': 0.5090252707581228, 'rte_test_eval_loss': 0.6928142309188843, 'rte_test_eval_acc': 0.5090252707581228, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0/runs/May14_03-30-12_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'uniting_learning_rate': 0.001, 'uniting_epochs': 10, 'train_uniting_model': True, 'method': 'finetune', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
{'time': '2024-05-14 03:50:37.292866', 'rte_dev_eval_loss': 0.6936927437782288, 'rte_dev_eval_acc': 0.5054151624548736, 'rte_test_eval_loss': 0.6936927437782288, 'rte_test_eval_acc': 0.5054151624548736, 'model_name_or_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'config_name': None, 'tokenizer_name': None, 'cache_dir': 'model_files', 'few_shot_type': 'finetune', 'random_segment': False, 'use_lm_head': 1, 'log_file_store': '../log_files/RTE', 'use_CLS_linearhead': 0, 'l1_reg': 0.0, 'graft_model_path': '/data/yekeming/project/neurips2024/uniting4nlp/models/roberta-base', 'model_type': 'roberta', 'output_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'overwrite_output_dir': True, 'do_train': False, 'do_eval': True, 'do_predict': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': 1000, 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0/runs/May14_03-46-50_ubuntu', 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>, 'logging_first_step': False, 'logging_steps': 100, 'logging_nan_inf_filter': True, 'save_strategy': <IntervalStrategy.STEPS: 'steps'>, 'save_steps': 500, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'data_seed': None, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': <OptimizerNames.ADAMW_HF: 'adamw_hf'>, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>, 'hub_token': None, 'gradient_checkpointing': False, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, 'mp_parameters': '', 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'fix_embeddings': True, 'fix_head': True, 'save_at_last': False, 'no_train': True, 'no_predict': False, 'optimizer': 'SGD', 'train_head': 0, 'save_every_ckpt': 0, 'train_bias_only': False, 'uniting_model_ckpt': '../ckpt_paths/RTE/RTE-finetune-roberta-base-finetune-32-1e-3-seed0', 'uniting_learning_rate': 0.001, 'uniting_epochs': 20, 'train_uniting_model': True, 'method': 'finetune', '_n_gpu': 1, '__cached__setup_devices': device(type='cuda', index=0), 'task_name': 'rte', 'data_dir': '../data/original/RTE', 'max_seq_length': 256, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*?*mask*,*+sentl_1**sep+*', 'mapping': "{'not_entailment':'No','entailment':'Yes'}", 'template_path': None, 'mapping_path': None, 'prompt_path': None, 'template_id': None, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 240, 'other_sent_limit': None, 'use_full_length': None, 'max_length_per_example': 128, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': False, 'template_list': None, 'autoregressive': False}
